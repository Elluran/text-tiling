{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "from torch import nn\n",
    "import transformers\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from utils import *\n",
    "from transformers import AutoTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperDialseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/SuperDialseg/segmentation_file_train.json\") as f:\n",
    "    super_dialseg_json = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "acc_dialog = []\n",
    "for message in super_dialseg_json[\"dial_data\"][\"superseg-v2\"][123][\"turns\"]:\n",
    "    # acc_dialog.append()\n",
    "    # print(message[\"utterance\"])\n",
    "    print(message[\"segmentation_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет Анны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = r\"datasets/dataset_v1.xml\"\n",
    "root = ET.parse(fpath).getroot()\n",
    "\n",
    "ids = []\n",
    "situations = {}\n",
    "\n",
    "\n",
    "def namespace(element):\n",
    "    m = re.match(r\"\\{.*\\}\", element)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "\n",
    "for child in root:\n",
    "    text = []\n",
    "    for attr in child:\n",
    "        for a in attr:\n",
    "            if \"Text\" in a.tag:\n",
    "                text.append(str(a.text))\n",
    "    ns = namespace(a.tag)\n",
    "    if ns not in situations:\n",
    "        situations[ns] = []\n",
    "        situations[ns].append(text)\n",
    "    else:\n",
    "        situations[ns].append(text)\n",
    "\n",
    "    msg = [int(attr.attrib[\"id\"]) for attr in child]\n",
    "    ids.append((msg[0], msg[-1]))\n",
    "    # situations.append(text)\n",
    "\n",
    "ids = sorted(ids, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_situation(sit):\n",
    "    for num, message in enumerate(sit):\n",
    "        print(str(num) + \":\", message.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Starting a new part time job today. Unfortunately for my FCC work it's PHP. On the bright side, they are going to pay me. Hope it goes well.\n",
      "1: Pay is always good, @StevenKW :)\n",
      "2: This is true :) @admhlt hopefully I learn a lot.\n",
      "3: My company deals with C, Java, and C#. I don't work on that side but I'm exposed to APIs and programming terms a lot, so I kind of pick up stuff along the way. Approach PHP in that way and it'll be tangentially useful. :)\n",
      "4: @StevenKW  Well you’ve got to pay the bills! It’s a shame you don’t get to do double duty using JS for the gig \n",
      "5: that’d be so ideal\n",
      "6: there are lots of PHP jobs still kicking around, so once you know both you’ll be that much more employable \n",
      "7: @StevenKW If it's a new project, you should just start it in JS :P See if they notice haha\n",
      "8: @figitalboy yeah I was really focusing on JS so I was surprised to get the gig. But yeah I was in school all 2014 with no income so yeah I need to pay some bills.\n",
      "9: I hear you man. Congrats on finding the gig!\n",
      "10: @sircharleswatson This is a junior position. I am hoping I'll get some mentorship and training along the way.\n"
     ]
    }
   ],
   "source": [
    "print_situation(situations[\"{JobSearch}\"][15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ubuntu Dialogue Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDC = pd.read_csv(\"datasets/UDC/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"OOo should be there and installed by default, yes  use UNKNOWN in cases where a bug component doesn't exist  uh? every British keyboard I've used is pc105  \",\n",
       " ' for me, orinoco_cs is loaded my the pcmcia layer  ',\n",
       " ' oh, you mean all of this is just plugdev?  ',\n",
       " ' the plugdev group and all admin tools expecting sudo to work are the first two major issues i can see  ',\n",
       " ' sourcing the bash completion script slows down starting a shell by a good second for me :(  ',\n",
       " ' there is that :/  ',\n",
       " ' interestingly, though, ntpdate runs before pcmcia  ',\n",
       " ' urgh :)  ',\n",
       " ' oh, this is the \"we must install exactly the same set of packages on every system!\" thing  I keep meaning to jump up and down on mdz and jdub\\'s heads until they relent in the case of pcmcia-cs :)  ',\n",
       " ' surely that can be detected at install time :)  ',\n",
       " ' yes, and debian-installer does so, but we have explicitly overridden this by policy  which I think is wrong in the PCMCIA case  ',\n",
       " ' ditto  ',\n",
       " ' ']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDC[\"Context\"][5].replace(\"__eou__\", \"\").split(\"__eot__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes. same binary packages. __eou__'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDC[\"Utterance\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDC_df = pd.read_csv(\"datasets/ubuntu_dialogue_corpus/dialogueText.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDC_df2 = pd.read_csv(\"datasets/ubuntu_dialogue_corpus/dialogueText_196.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>dialogueID</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>1.tsv</td>\n",
       "      <td>2004-11-23T11:49:00.000Z</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>any ideas why java plugin takes so long to load?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>1.tsv</td>\n",
       "      <td>2004-11-23T11:49:00.000Z</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>java 1.4?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301</td>\n",
       "      <td>1.tsv</td>\n",
       "      <td>2004-11-23T11:49:00.000Z</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>1.tsv</td>\n",
       "      <td>2004-11-23T11:49:00.000Z</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>java 1.5 loads _much_ faster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301</td>\n",
       "      <td>1.tsv</td>\n",
       "      <td>2004-11-23T11:50:00.000Z</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>noneus: how can i get 1.5 is there a .deb some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9212872</th>\n",
       "      <td>13</td>\n",
       "      <td>3676.tsv</td>\n",
       "      <td>2012-07-07T20:17:00.000Z</td>\n",
       "      <td>MonkeyDust</td>\n",
       "      <td>legolas</td>\n",
       "      <td>= arian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9212873</th>\n",
       "      <td>13</td>\n",
       "      <td>3676.tsv</td>\n",
       "      <td>2012-07-07T20:18:00.000Z</td>\n",
       "      <td>MonkeyDust</td>\n",
       "      <td>legolas</td>\n",
       "      <td>observation and deduction, dear watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9212874</th>\n",
       "      <td>13</td>\n",
       "      <td>16586.tsv</td>\n",
       "      <td>2008-07-25T01:53:00.000Z</td>\n",
       "      <td>linuxfce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am trying to install nvidia drivers from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9212875</th>\n",
       "      <td>13</td>\n",
       "      <td>16586.tsv</td>\n",
       "      <td>2008-07-25T01:53:00.000Z</td>\n",
       "      <td>linuxfce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>how do i enter runlevel 3? when i try telinit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9212876</th>\n",
       "      <td>13</td>\n",
       "      <td>16586.tsv</td>\n",
       "      <td>2008-07-25T01:54:00.000Z</td>\n",
       "      <td>linuxfce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anyone know how to enter runlevel 3 in ubuntu?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9212877 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         folder dialogueID                      date        from       to  \\\n",
       "0           301      1.tsv  2004-11-23T11:49:00.000Z     stuNNed      NaN   \n",
       "1           301      1.tsv  2004-11-23T11:49:00.000Z     crimsun  stuNNed   \n",
       "2           301      1.tsv  2004-11-23T11:49:00.000Z     stuNNed  crimsun   \n",
       "3           301      1.tsv  2004-11-23T11:49:00.000Z     crimsun  stuNNed   \n",
       "4           301      1.tsv  2004-11-23T11:50:00.000Z     stuNNed  crimsun   \n",
       "...         ...        ...                       ...         ...      ...   \n",
       "9212872      13   3676.tsv  2012-07-07T20:17:00.000Z  MonkeyDust  legolas   \n",
       "9212873      13   3676.tsv  2012-07-07T20:18:00.000Z  MonkeyDust  legolas   \n",
       "9212874      13  16586.tsv  2008-07-25T01:53:00.000Z    linuxfce      NaN   \n",
       "9212875      13  16586.tsv  2008-07-25T01:53:00.000Z    linuxfce      NaN   \n",
       "9212876      13  16586.tsv  2008-07-25T01:54:00.000Z    linuxfce      NaN   \n",
       "\n",
       "                                                      text  \n",
       "0         any ideas why java plugin takes so long to load?  \n",
       "1                                                java 1.4?  \n",
       "2                                                      yes  \n",
       "3                             java 1.5 loads _much_ faster  \n",
       "4        noneus: how can i get 1.5 is there a .deb some...  \n",
       "...                                                    ...  \n",
       "9212872                                            = arian  \n",
       "9212873             observation and deduction, dear watson  \n",
       "9212874  i am trying to install nvidia drivers from the...  \n",
       "9212875  how do i enter runlevel 3? when i try telinit ...  \n",
       "9212876     anyone know how to enter runlevel 3 in ubuntu?  \n",
       "\n",
       "[9212877 rows x 6 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDC_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1038324"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(UDC_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>dialogueID</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>126125.tsv</td>\n",
       "      <td>2008-04-23T14:55:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello folks, please help me a bit with the fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>126125.tsv</td>\n",
       "      <td>2008-04-23T14:56:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did I choose a bad channel? I ask because you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126125.tsv</td>\n",
       "      <td>2008-04-23T14:57:00.000Z</td>\n",
       "      <td>lordleemo</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>the second sentence is better english   and we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64545.tsv</td>\n",
       "      <td>2009-08-01T06:22:00.000Z</td>\n",
       "      <td>mechtech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sock Puppe?t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>64545.tsv</td>\n",
       "      <td>2009-08-01T06:22:00.000Z</td>\n",
       "      <td>mechtech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WTF?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038319</th>\n",
       "      <td>3</td>\n",
       "      <td>51506.tsv</td>\n",
       "      <td>2012-01-31T10:56:00.000Z</td>\n",
       "      <td>DJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anyone on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038320</th>\n",
       "      <td>3</td>\n",
       "      <td>51506.tsv</td>\n",
       "      <td>2012-01-31T10:56:00.000Z</td>\n",
       "      <td>aeon-ltd</td>\n",
       "      <td>DJ</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038321</th>\n",
       "      <td>3</td>\n",
       "      <td>99669.tsv</td>\n",
       "      <td>2008-11-16T20:11:00.000Z</td>\n",
       "      <td>KR-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>can I get a pastebin of someones menu.lst with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038322</th>\n",
       "      <td>3</td>\n",
       "      <td>99669.tsv</td>\n",
       "      <td>2008-11-16T20:12:00.000Z</td>\n",
       "      <td>outbackwifi</td>\n",
       "      <td>KR-data</td>\n",
       "      <td>http://pastebin.com/fe921690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038323</th>\n",
       "      <td>3</td>\n",
       "      <td>99669.tsv</td>\n",
       "      <td>2008-11-16T20:13:00.000Z</td>\n",
       "      <td>KR-data</td>\n",
       "      <td>outbackwifi</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1038324 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         folder  dialogueID                      date         from  \\\n",
       "0             3  126125.tsv  2008-04-23T14:55:00.000Z    bad_image   \n",
       "1             3  126125.tsv  2008-04-23T14:56:00.000Z    bad_image   \n",
       "2             3  126125.tsv  2008-04-23T14:57:00.000Z    lordleemo   \n",
       "3             3   64545.tsv  2009-08-01T06:22:00.000Z     mechtech   \n",
       "4             3   64545.tsv  2009-08-01T06:22:00.000Z     mechtech   \n",
       "...         ...         ...                       ...          ...   \n",
       "1038319       3   51506.tsv  2012-01-31T10:56:00.000Z           DJ   \n",
       "1038320       3   51506.tsv  2012-01-31T10:56:00.000Z     aeon-ltd   \n",
       "1038321       3   99669.tsv  2008-11-16T20:11:00.000Z      KR-data   \n",
       "1038322       3   99669.tsv  2008-11-16T20:12:00.000Z  outbackwifi   \n",
       "1038323       3   99669.tsv  2008-11-16T20:13:00.000Z      KR-data   \n",
       "\n",
       "                  to                                               text  \n",
       "0                NaN  Hello folks, please help me a bit with the fol...  \n",
       "1                NaN  Did I choose a bad channel? I ask because you ...  \n",
       "2          bad_image  the second sentence is better english   and we...  \n",
       "3                NaN                                       Sock Puppe?t  \n",
       "4                NaN                                               WTF?  \n",
       "...              ...                                                ...  \n",
       "1038319          NaN                                         anyone on?  \n",
       "1038320           DJ                                                yes  \n",
       "1038321          NaN  can I get a pastebin of someones menu.lst with...  \n",
       "1038322      KR-data                       http://pastebin.com/fe921690  \n",
       "1038323  outbackwifi                                             thanks  \n",
       "\n",
       "[1038324 rows x 6 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "udc_dialogs = [list(x[\"text\"]) for _, x in UDC_df.groupby(\"dialogueID\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346108"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(udc_dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bonsoir', 'nobody speak french here?', \"I do, but there's also #ubuntu-fr\"]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udc_dialogs[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(x) for x in udc_dialogs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freecodecamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_764520/1581645885.py:1: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_freecodecamp = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "df_freecodecamp = pd.read_csv(\n",
    "    \"datasets/freecodecamp/freecodecamp_casual_chatroom_anon.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: no legumes either\n",
      "1: That bullet proof coffee sounds insane.\n",
      "2: That guy has huge eyes.\n",
      "3: @54a47e0cdb8155e6700e486e It is. but it works. some people just can't handle the taste :P\n",
      "4: They guy that came up with the idea is kind of a joke though...\n",
      "5: that sounds like torture actually :)\n",
      "6: the*\n",
      "7: I might try it out for fun-just one bullet proof coffee that is.\n",
      "8: @54a44bbbdb8155e6700e47de I agree. he's pretty extreme lol\n",
      "9: he's like the Bear Grylls of diets\n",
      "10: haha\n",
      "11: I have zero intention of doing the whole diet bit of it, I just want the nommy creamy fatty coffee\n",
      "12: and the energy\n",
      "13: I can't help but laugh at my own joke/reference lol\n",
      "14: Anyone near LA/Santa Monica, CA want to host me and my wife for a week or two? :D\n",
      "15: haha\n",
      "16: I would if I didn’t have my son and his family camping in my den\n",
      "17: tho we aren’t that close to santa monica\n",
      "18: How close is \"not that close\"? lol\n",
      "19: hmm, 2 hour drive, but thats because the freeways are a nightmare :)\n",
      "20: Here's one of the things I love about Meteor and everything that surrounds it's structure...the way that things associated to Meteor directly reference back to the branding idea of an actual physical meteor object.\n",
      "21: Atmosphere as the package manager\n",
      "22: Meteorites as the package installer\n",
      "23: The oortcloud...etc\n",
      "24: HAH I’m using skitch for bills my kids owe me, pink pointers everywhere!\n",
      "25: I’m the most annoying mom\n",
      "26: @5466246ddb8155e6700d4a1a Meteorites is not a thing anymore :P\n",
      "27: lame\n",
      "28: it is now the term used to describe someone who is a meteor developer\n",
      "29: (and it was replaced by atmosphere)\n"
     ]
    }
   ],
   "source": [
    "print_situation(df_freecodecamp[\"text\"][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"daily_dialog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset[\"validation\"]).drop([\"act\", \"emotion\"], axis=1)[\"dialog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df1 = pd.DataFrame(dataset[\"train\"]).drop([\"act\", \"emotion\"], axis=1)[\"dialog\"]\n",
    "# df2 = pd.DataFrame(dataset[\"validation\"]).drop([\"act\", \"emotion\"], axis=1)[\"dialog\"]\n",
    "# df3 = pd.DataFrame(dataset[\"test\"]).drop([\"act\", \"emotion\"], axis=1)[\"dialog\"]\n",
    "\n",
    "# df = pd.concat([df1, df2, df3]).reset_index(drop=True)\n",
    "\n",
    "# df_train = df\n",
    "\n",
    "dialogs = []\n",
    "\n",
    "for dialog in situations.values():\n",
    "    for situation in dialog:\n",
    "        dialogs.append(situation)\n",
    "\n",
    "df2 = pd.DataFrame({\"dialog\": dialogs})\n",
    "\n",
    "# print(len(df))\n",
    "\n",
    "# df = pd.concat([df, df2[\"dialog\"]])\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "# print(len(df))\n",
    "\n",
    "# df_train, df_test = train_test_split(df, train_size=0.6, random_state=42)\n",
    "# df2 = pd.concat([df2[\"dialog\"], df3])\n",
    "df_test = df2[\"dialog\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_super_dialseg(dataset_dict):\n",
    "    # dataset_dict = {\"messages\": [], \"boundaries\": [], \"boundaries_mask\": []}\n",
    "\n",
    "    for dialog in super_dialseg_json[\"dial_data\"][\"superseg-v2\"]:\n",
    "        messages = []\n",
    "        boundaries = []\n",
    "        boundaries_mask = []\n",
    "        \n",
    "        for num, message in enumerate(dialog[\"turns\"]):\n",
    "            messages.append(message[\"utterance\"])\n",
    "            # print(message[\"utterance\"])\n",
    "            boundaries_mask.append(message[\"segmentation_label\"])\n",
    "            if message[\"segmentation_label\"]:\n",
    "                boundaries.append(num)\n",
    "\n",
    "        dataset_dict[\"messages\"].append(np.array(messages))\n",
    "        dataset_dict[\"boundaries\"].append(np.array(boundaries[:-1]))\n",
    "        dataset_dict[\"boundaries_mask\"].append(np.array(boundaries_mask[:-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_dataset():\n",
    "    random_generator = np.random.default_rng(42)\n",
    "\n",
    "    dataset_dict = {\"messages\": [], \"boundaries\": [], \"boundaries_mask\": []}\n",
    "\n",
    "    # for i in range(100):\n",
    "    #     n_samples = df_test.sample(5, random_state=random_generator)\n",
    "    #     seg_boundaries = []\n",
    "    #     acc_sum = 0\n",
    "    #     for sample in n_samples[:-1]:\n",
    "    #         seg_boundaries.append(acc_sum + len(sample) - 1)\n",
    "    #         acc_sum += len(sample)\n",
    "    #     acc_sum += len(n_samples.iloc[-1])\n",
    "\n",
    "    #     seg_boundaries_mask = np.zeros(acc_sum - 1, dtype=np.int8)\n",
    "    #     dataset_dict[\"messages\"].append(np.concatenate(n_samples.to_numpy()))\n",
    "    #     dataset_dict[\"boundaries\"].append(seg_boundaries)\n",
    "    #     for pos in seg_boundaries:\n",
    "    #         seg_boundaries_mask[pos] = 1\n",
    "    #     dataset_dict[\"boundaries_mask\"].append(seg_boundaries_mask)\n",
    "\n",
    "        \n",
    "    process_super_dialseg(dataset_dict)\n",
    "\n",
    "    return pd.DataFrame(dataset_dict)\n",
    "\n",
    "\n",
    "test_df = generate_test_dataset()\n",
    "test_df\n",
    "\n",
    "\n",
    "\n",
    "test_df.to_csv(f\"synthetic_{len(test_df)}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[\"messages\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[\"boundaries_mask\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[1][\"boundaries_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "messages           [Can you help me with planing the benefits for...\n",
       "boundaries                                                    [4, 6]\n",
       "boundaries_mask                    [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Can you help me with planing the benefits for my survivors?',\n",
       "       'Are you planning for the future of your survivors?',\n",
       "       'Not right now.',\n",
       "       'But I want to know if my family would get any help from Social Security after my passing.',\n",
       "       'yes, Social Security can help your family if you have earned enough credits through your work.',\n",
       "       'And what about my widow, what benefits would she receive?',\n",
       "       \"She can get reduced benefits as early as age 60 or full benefits at full retirement age. If she's 50 years old she could get the benefits if she's disabled and her disability started 7 years or earlier before your death.\",\n",
       "       'what if she remarries after my death?',\n",
       "       'if she remarries after age 60, 50 if disabled, she would still qualify for the benefits on your social security records.',\n",
       "       'And if she receives a pension not covered by Social Security?',\n",
       "       \"If it's a pension based on work then their Social Security benefits as a survivor could be affected.\"],\n",
       "      dtype='<U220')"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[1][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5979709845399418"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_random_mean_windowdiff(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:52,  1.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3401264047570903"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate_mean_windowdiff(\n",
    "#     test_df[:40], scorer=scorer_all_mpnet, smoothing_strategy=\"depth\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_messages = df_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oh , man . I had the best supper last night . My wife made a stir-fry and it was amazing ! ',\n",
       " ' I love stir fry crispy bitesize vegetables covered in a mixture of soy sauce and oyster sauce . Wilted greens and fresh bean sprouts . Throw in some onion and garlic and ginger ! Mmm ! Mmm ! It ’ s almost lunchtime . I would die for a plate of stir fry right now ! ',\n",
       " ' Well , you can keep the vegetables , I ’ ll take the meat . The stir fry my wife made was really hearty , with chunks of beef and slivers of bell peppers and onion ... ',\n",
       " ' What ? You call that a stir fry ? More meat than vegetables ? That ’ s the worst insult you could throw at a Chinese stir fry . What a disgrace to the wok she fried it in ! What you had is equivalent to a fajita without the wrap ! ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_messages.iloc[1].dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_messages = df_train[df_train.apply(len) > 30].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_messages_exploded = df_train.explode()\n",
    "df_train_messages_exploded = df_train_messages_exploded[df_train_messages_exploded.apply(len) > 30].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Why , this is the most interesting film ! '"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_messages_exploded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh , man . I had the best supper last night . My wife made a stir-fry and it was amazing ! '"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_messages_exploded[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7533\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "rnd_gen = np.random.default_rng(42)\n",
    "\n",
    "message_pairs = []\n",
    "labels = []\n",
    "for dialog in df_train_messages.iterrows():\n",
    "    messages = dialog[1].dialog\n",
    "    for i in range(len(messages) - 1):\n",
    "        message_1 = messages[i]\n",
    "        message_2 = messages[i + 1]\n",
    "        if len(message_1.split()) < 30 and len(message_2.split()) < 30:\n",
    "            continue\n",
    "\n",
    "    \n",
    "        message_3 = random.choice(df_train_messages_exploded)\n",
    "        while message_3 == message_2 or len(message_3) < 30:\n",
    "            message_3 = random.choice(df_train_messages_exploded)\n",
    "\n",
    "        message_pairs.append(((message_1, message_2), (message_1, message_3))) \n",
    "\n",
    "        labels.append((1, 0))\n",
    "\n",
    "pos_samples_num = len(labels)\n",
    "\n",
    "# for i in range(pos_samples_num):\n",
    "#     dialog = df_train_messages .sample(1, random_state=rnd_gen)\n",
    "#     message_1 = random.choice(dialog[\"dialog\"].iloc[0])\n",
    "#     dialog = df_train_messages .sample(1, random_state=rnd_gen)\n",
    "#     message_2 = random.choice(dialog[\"dialog\"].iloc[0])\n",
    "\n",
    "#     if message_1 == message_2:\n",
    "#         i -= 1\n",
    "#         continue\n",
    "\n",
    "#     message_pairs.append((message_1 , message_2)) \n",
    "#     labels.append(0)\n",
    "\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_pairs[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save = pd.DataFrame({\"message_pairs\": message_pairs, \"labels\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((' The whole-wheat loaf is 45 cents , the white loaves are 35 cents each , the baguette is 27 cents and the rolls are eight cents each . That makes two dollars fifty-seven cents . ',\n",
       "  ' There you go . '),\n",
       " (' The whole-wheat loaf is 45 cents , the white loaves are 35 cents each , the baguette is 27 cents and the rolls are eight cents each . That makes two dollars fifty-seven cents . ',\n",
       "  \" It is very dull , and the production isn't very satisfactory , either . \"))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_save.message_pairs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save.to_csv(\"message_pairs_train3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'message_pairs_train2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mast\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mmessage_pairs_train2.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, converters\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmessage_pairs\u001b[39;49m\u001b[39m\"\u001b[39;49m: ast\u001b[39m.\u001b[39;49mliteral_eval})\n",
      "File \u001b[0;32m/mnt/ssd1/code/chat-project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/mnt/ssd1/code/chat-project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/mnt/ssd1/code/chat-project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/mnt/ssd1/code/chat-project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/mnt/ssd1/code/chat-project/venv/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'message_pairs_train2.csv'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "df = pd.read_csv(\"message_pairs_train.csv\", converters={\"message_pairs\": ast.literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save.to_csv(\"message_pairs_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForNextSentencePrediction(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (cls): BertOnlyNSPHead(\n",
       "        (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # !pip install peft\n",
    "# import peft\n",
    "# from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1, target_modules=[\"output.dense\", \"intermediate.dense\"]\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# model.load_state_dict(torch.load(\"bert_v4.bin\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"bert_v2.bin\"))\n",
    "# model.eval()\n",
    "\n",
    "model = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\").to(\"cuda:0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model.load_state_dict(torch.load(\"bert_v13.bin\"))\n",
    "model.eval()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_trained_bert(messages: list[str]) -> list[float]:\n",
    "    scores = []\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(len(messages) - 1):\n",
    "        j = i + 1\n",
    "\n",
    "        tokenized_input = {}\n",
    "        if tokenizer:\n",
    "            tokenized_input = tokenizer(\n",
    "                messages[i], messages[j], max_length=200, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model.forward(**tokenized_input).logits\n",
    "            # logits2 = model2.forward(**tokenized_input).logits\n",
    "\n",
    "        score = F.softmax(logits, dim=1)[0][0]\n",
    "        # score2 = F.softmax(logits2, dim=1)[0][0]\n",
    "        # if abs(score2 - score) > 0.4:\n",
    "        #     print(messages[i])\n",
    "        #     print(messages[j])\n",
    "        #     print(score.item(), score2.item())\n",
    "        #     print(\"===============\")\n",
    "        # scores.append(score.item())\n",
    "        # print(score.item())\n",
    "        # print(logits)\n",
    "        # score = float(logits[0][0] > logits[0][1])\n",
    "        # print(score)\n",
    "        scores.append(score)\n",
    "\n",
    "    model.train()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:21,  1.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5230348124098125"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:22,  1.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5230348124098125"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:21,  1.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5154103535353535"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:22,  1.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5176488095238095"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:53,  1.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34152871569022814"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:39,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3062774652885638"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:100], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_cse_tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/unsup-simcse-bert-base-uncased\")\n",
    "simccse = AutoModel.from_pretrained(\"princeton-nlp/unsup-simcse-bert-base-uncased\")\n",
    "simccse.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8224e-02, -1.5342e-01,  2.4753e-02, -2.4195e-01,  1.0743e-02,\n",
       "         -1.2324e-01, -2.8514e-01,  3.0996e-01, -3.4264e-01, -7.2695e-02,\n",
       "          2.2181e-01,  8.9207e-02,  1.2024e-01,  3.9563e-01,  9.5287e-02,\n",
       "          2.9778e-01,  4.0870e-01, -1.5835e-01, -1.1901e-01,  1.9070e-01,\n",
       "          2.1353e-01, -1.4015e-01, -3.6019e-01,  4.5661e-01, -6.0788e-02,\n",
       "          2.2946e-01,  1.3560e-01,  2.7423e-02,  1.3670e-01,  2.0928e-01,\n",
       "         -1.3890e-01,  1.7705e-03,  1.5460e-02, -1.9037e-01, -1.6040e-01,\n",
       "         -4.9947e-02, -3.9888e-01, -3.4945e-01,  3.1839e-01,  9.3402e-02,\n",
       "         -2.0689e-01, -2.9903e-01,  1.2119e-03, -1.4769e-02, -2.1322e-03,\n",
       "          8.7020e-02, -2.4439e-01, -8.7038e-02,  7.6707e-04,  1.8775e-02,\n",
       "          2.5070e-01, -4.8939e-01, -5.9470e-02,  1.9797e-01, -3.5841e-01,\n",
       "         -5.5158e-02, -4.5313e-01,  9.9714e-02,  1.6465e-01,  2.5107e-01,\n",
       "          2.1619e-01,  1.8364e-03, -1.4387e-01,  1.6342e-01,  2.0781e-01,\n",
       "          7.1705e-02,  2.5070e-01, -2.4735e-01,  1.5514e-01,  3.6534e-01,\n",
       "         -1.7563e-01,  7.7367e-02,  1.8513e-01,  1.0170e-01,  1.5266e-01,\n",
       "          3.9254e-01, -3.4559e-01, -6.0593e-02,  8.4394e-02,  2.5296e-01,\n",
       "         -3.9593e-01,  2.6399e-01,  1.4796e-01, -5.5417e-02, -2.3521e-01,\n",
       "          3.2073e-01, -1.8859e-01, -5.9604e-02,  3.5330e-02,  1.0975e-01,\n",
       "          1.0059e-01,  1.0057e-02, -2.3430e-01,  4.5791e-02, -2.5980e-01,\n",
       "         -4.6969e-01,  3.3338e-01,  3.8781e-02, -1.1188e-01, -7.1642e-02,\n",
       "          4.3596e-04,  3.0884e-02, -4.7832e-02, -1.7129e-01,  1.7191e-01,\n",
       "          3.1956e-02,  2.6446e-01,  1.9979e-01, -6.2992e-02, -1.0939e-01,\n",
       "         -1.4719e-01,  2.5728e-01, -2.6794e-01,  6.4576e-02, -1.4879e-01,\n",
       "         -3.0844e-01, -4.1242e-01,  2.1241e-01, -8.2433e-02,  2.7650e-01,\n",
       "         -5.2003e-01,  1.0057e-01,  4.2369e-01,  2.6599e-01, -1.1992e-01,\n",
       "          1.4841e-01,  9.9659e-02,  2.7260e-01, -2.6345e-01,  1.5408e-02,\n",
       "         -1.5577e-01,  2.5446e-01,  1.1398e-01, -1.6790e-01,  2.1813e-01,\n",
       "         -1.1810e-01, -1.4947e-01, -2.6148e-01,  4.0807e-02, -5.5779e-01,\n",
       "          6.6822e-02,  1.4854e-01,  9.0537e-02,  5.1852e-02, -7.9437e-02,\n",
       "         -4.7426e-01,  1.5107e-01, -1.0906e-01,  2.0600e-01,  1.6845e-01,\n",
       "          4.0940e-01, -1.4697e-01, -4.0973e-02,  1.7052e-01,  1.4547e-01,\n",
       "          6.9188e-02,  2.1516e-01, -8.3424e-02,  1.3375e-01, -8.1704e-02,\n",
       "          4.4476e-01, -3.7278e-01, -5.2216e-02,  2.0204e-01,  4.8980e-01,\n",
       "         -1.8088e-01, -2.2227e-01,  1.6359e-01,  3.4115e-01,  1.1917e-01,\n",
       "         -2.2438e-01,  9.8272e-02,  1.2303e-01,  1.2782e-01, -1.6188e-01,\n",
       "         -3.6048e-01,  1.6514e-01,  1.4635e-01, -1.5739e-01,  6.6971e-02,\n",
       "          2.6931e-01, -2.2613e-01,  9.6348e-02, -3.8178e-02, -2.2917e-02,\n",
       "         -4.3584e-02, -3.1633e-01, -1.4819e-01, -9.9567e-02,  2.7970e-01,\n",
       "          7.8653e-02, -3.2946e-01,  3.3766e-01, -2.2204e-01,  4.4834e-02,\n",
       "         -7.4972e-02, -3.6147e-01, -9.0978e-02, -2.4002e-02,  2.2122e-01,\n",
       "          2.4907e-01, -2.4924e-01, -1.0424e-01,  7.4666e-02,  1.5561e-01,\n",
       "         -1.3679e-01,  2.9828e-01,  3.7637e-02, -2.4228e-01,  6.0145e-02,\n",
       "         -2.1130e-01,  2.1198e-02,  2.0697e-01, -1.6171e-01, -5.2058e-01,\n",
       "         -2.1936e-01,  9.5316e-02, -5.4533e-01, -2.2246e-01, -3.1353e-01,\n",
       "         -7.6816e-03, -2.6052e-01, -2.7042e-01, -3.7780e-02,  5.4543e-02,\n",
       "         -1.8411e-01, -5.1108e-02, -2.8612e-02,  1.9239e-01, -1.0916e-01,\n",
       "          7.6847e-02, -1.6269e-01, -1.1070e-01, -3.6757e-02,  2.7420e-01,\n",
       "          9.2604e-03,  5.2852e-01,  1.8176e-01,  2.4194e-01, -4.7833e-01,\n",
       "          3.2383e-01, -3.3024e-01, -4.1357e-01,  2.1179e-01,  2.7460e-01,\n",
       "          2.0514e-01, -4.9825e-02,  1.3606e-01,  4.6177e-01, -7.4581e-02,\n",
       "         -1.3162e-01, -2.7905e-01, -8.0557e-02, -1.3070e-01, -3.2498e-01,\n",
       "         -1.0513e-01,  2.2664e-01, -7.0586e-02,  5.9058e-02,  5.7666e-01,\n",
       "         -2.1076e-01,  2.0941e-01,  4.2305e-02,  2.0765e-01,  2.7098e-01,\n",
       "         -3.1435e-01, -1.2657e-01, -5.1232e-02,  4.9135e-02,  8.9926e-02,\n",
       "         -5.7614e-02,  2.2784e-01, -6.7047e-02, -9.4773e-02, -1.9217e-01,\n",
       "          1.6926e-01, -3.6791e-02,  2.0791e-01, -7.1652e-02, -5.8047e-02,\n",
       "          2.2826e-02, -3.0604e-02, -6.0645e-02, -2.2513e-02, -1.0985e-02,\n",
       "          3.1651e-02, -1.6154e-01,  4.8899e-02, -1.4989e-01, -3.9162e-01,\n",
       "          6.7670e-02,  7.1979e-02,  5.3627e-02, -7.8135e-02, -2.2543e-01,\n",
       "         -1.6513e-01,  2.8765e-01, -4.9334e-02,  9.6569e-03, -5.5087e-02,\n",
       "          2.3066e-01,  1.6227e-01,  1.7413e-01, -1.2240e-01,  2.8071e-01,\n",
       "         -5.0762e-01,  1.3950e-01, -3.1520e-01, -3.9318e-01,  3.7268e-01,\n",
       "          2.8821e-01, -3.1260e-02, -4.2232e-02, -7.0117e-02, -1.6703e-01,\n",
       "          1.9023e-01, -2.6899e-02,  1.7947e-01,  2.4295e-01, -3.0711e-01,\n",
       "          9.6516e-02,  1.0408e-01, -2.9337e-01,  3.1367e-01, -1.1224e-01,\n",
       "          2.5234e-02,  1.0478e-02,  1.3253e-01,  3.4217e-01,  2.7969e-01,\n",
       "          3.4042e-02,  7.6939e-02, -1.2793e-01, -2.2756e-01,  1.3140e-01,\n",
       "         -1.6591e-01,  1.7039e-01, -3.1287e-01, -8.6800e-02,  4.9676e-02,\n",
       "         -3.6190e-01,  9.5820e-03, -3.2384e-02, -4.5563e-01, -4.7895e-02,\n",
       "         -2.6456e-01,  2.5499e-01, -4.0055e-01, -2.0930e-01,  2.1938e-01,\n",
       "          1.5393e-01, -4.0428e-01,  1.3287e-01, -1.6913e-01,  5.3321e-02,\n",
       "          1.1889e-02,  2.3128e-01,  6.0235e-02, -1.3437e-01, -6.8145e-02,\n",
       "          2.0027e-01, -3.3276e-01,  1.8527e-01, -2.1742e-01, -4.2479e-01,\n",
       "          2.0491e-01,  1.5095e-02,  5.6801e-02,  2.0809e-01,  4.3409e-02,\n",
       "          2.5385e-01, -4.9374e-01, -1.5692e-02,  1.2855e-01, -2.4226e-01,\n",
       "          1.2808e-01,  1.9064e-01,  3.3580e-01, -4.8686e-02,  2.8583e-02,\n",
       "          3.2110e-01, -2.2469e-01, -8.2664e-02,  4.4538e-02,  4.0031e-01,\n",
       "          1.0896e-02, -2.9375e-01,  2.1294e-01,  1.5380e-01, -3.1927e-02,\n",
       "          4.3960e-01, -3.1088e-02, -2.3464e-02,  2.5918e-01, -3.6262e-01,\n",
       "         -4.3133e-01,  2.4185e-01,  5.4948e-02, -2.4966e-01, -7.1463e-03,\n",
       "         -3.9434e-02, -1.9802e-01, -2.3468e-01,  6.9758e-02,  2.4923e-01,\n",
       "         -2.1379e-01, -1.5986e-01,  1.2861e-01, -1.0975e-01,  3.8412e-01,\n",
       "         -2.0407e-01,  4.2331e-02, -1.4226e-03,  3.1066e-02,  5.3102e-02,\n",
       "          2.2797e-01,  1.8899e-01,  7.0424e-02,  5.4643e-02,  3.7330e-02,\n",
       "         -5.6453e-02, -2.6414e-01,  3.1783e-01,  1.8697e-01, -6.9806e-04,\n",
       "          2.6888e-01,  1.4499e-01, -2.0268e-01,  2.3156e-01,  1.6977e-01,\n",
       "         -8.5873e-02,  7.2714e-02,  3.0607e-01, -5.7639e-02, -1.5535e-01,\n",
       "         -7.5620e-02, -3.5556e-01, -2.5414e-01,  4.2957e-01, -7.2260e-02,\n",
       "          1.2735e-01,  1.5954e-01, -2.1934e-01, -2.2221e-01, -3.8175e-01,\n",
       "          1.9768e-01, -1.3163e-01,  1.8007e-02,  1.0114e-01, -1.4641e-01,\n",
       "          6.1617e-02, -9.9020e-02,  2.5252e-01, -1.3009e-01, -3.6495e-01,\n",
       "         -1.1798e-02, -1.4628e-01, -2.4176e-01, -8.9791e-02,  1.3119e-01,\n",
       "          3.6696e-01, -2.1329e-02,  8.0323e-02,  9.9449e-02, -2.2259e-01,\n",
       "          2.1827e-01, -2.9819e-01, -3.1150e-02, -3.5296e-02, -6.6925e-02,\n",
       "         -1.0425e-01,  1.6924e-01, -2.5658e-01, -3.6414e-01,  7.7893e-02,\n",
       "         -2.7664e-01, -4.4907e-01, -2.4915e-01,  1.3601e-01,  3.5580e-01,\n",
       "          1.1891e-01, -5.7860e-01, -1.1863e-01,  7.6272e-02, -6.7633e-02,\n",
       "         -3.2784e-01,  4.3629e-02, -4.3734e-01,  2.2506e-01,  1.9332e-01,\n",
       "         -1.7488e-02,  3.3944e-02, -3.7963e-01,  1.1029e-01, -3.2337e-01,\n",
       "         -5.2409e-02, -2.9743e-01,  9.6513e-03,  1.4916e-01,  1.0970e-01,\n",
       "         -9.1492e-03,  3.3922e-01, -1.3091e-01, -1.4764e-02, -1.5805e-01,\n",
       "         -1.2288e-01, -3.3437e-01,  2.3998e-01,  1.5234e-01,  9.3460e-02,\n",
       "          1.3997e-01, -2.1802e-01, -1.8071e-01,  3.4032e-01,  1.8085e-01,\n",
       "         -1.3555e-01,  3.3890e-01,  3.2579e-03, -2.6607e-01,  3.8978e-02,\n",
       "          4.7754e-02, -1.3387e-01, -2.1693e-01, -3.4539e-01,  1.6579e-02,\n",
       "          9.1899e-02, -1.0855e-01, -1.7753e-01,  4.1188e-01,  4.2354e-01,\n",
       "          1.7786e-01, -3.8309e-01,  2.1348e-01,  3.7291e-02, -3.2728e-02,\n",
       "         -2.5728e-03,  1.0790e-01, -1.8823e-01,  4.2108e-01,  6.0137e-02,\n",
       "          8.8532e-02,  1.0371e-02,  3.9389e-01, -9.7453e-02,  1.5582e-01,\n",
       "          1.6607e-01,  2.8302e-01, -1.9606e-01, -4.6544e-01,  8.4703e-02,\n",
       "         -9.2982e-02, -1.4410e-01, -1.6049e-01, -3.1423e-01,  2.0344e-01,\n",
       "          9.3581e-02,  3.2785e-01,  2.0897e-01, -3.8820e-02, -1.9180e-01,\n",
       "         -1.7507e-01, -3.1937e-01, -1.1249e-01, -1.5237e-01,  2.3850e-01,\n",
       "         -2.1942e-01, -2.2396e-02,  7.6144e-02,  4.8583e-02, -2.6557e-01,\n",
       "          1.0442e-01,  4.1105e-01, -7.8490e-02, -2.0557e-01, -9.6688e-02,\n",
       "         -3.1941e-01, -2.8177e-01,  1.3327e-01, -5.8338e-02, -1.9882e-01,\n",
       "         -4.5519e-01, -1.6094e-01, -2.1278e-01, -7.7787e-02, -2.2679e-01,\n",
       "         -1.4396e-01, -2.7749e-01,  3.5848e-02, -7.0808e-02, -5.0209e-01,\n",
       "         -3.2176e-01,  2.0079e-01,  3.4564e-01, -1.2473e-01,  5.2893e-02,\n",
       "         -1.6081e-01, -1.0819e-02, -2.9160e-01,  2.2710e-02, -3.2966e-01,\n",
       "         -1.0758e-01, -3.6097e-01,  4.3351e-03, -9.3769e-02,  9.4855e-02,\n",
       "         -2.1006e-01,  3.9439e-01, -1.8271e-01, -5.8657e-02,  1.3214e-01,\n",
       "         -2.8641e-01,  2.2022e-02,  4.1141e-01, -2.5898e-02,  2.2259e-01,\n",
       "          7.1556e-02, -1.3492e-01,  1.9613e-02,  1.6274e-01,  1.7301e-01,\n",
       "          2.7137e-01, -5.9276e-01, -1.2919e-02, -3.1276e-01, -1.4865e-01,\n",
       "          6.5586e-02, -1.3658e-02,  1.4375e-01,  1.0375e-01,  1.3046e-02,\n",
       "         -1.8799e-01, -7.5243e-02,  8.0417e-02, -2.8899e-01, -3.5515e-02,\n",
       "          3.8740e-02, -2.1858e-01, -3.7141e-01,  2.7703e-01,  1.4990e-01,\n",
       "          1.9622e-01, -6.1698e-01, -1.2615e-01, -6.2530e-02,  2.4265e-01,\n",
       "         -2.5022e-01,  2.8067e-02, -4.5653e-01,  2.6560e-01,  1.2509e-01,\n",
       "         -3.1823e-02, -2.5413e-01, -3.0402e-01,  1.8634e-01,  2.9060e-01,\n",
       "         -4.5203e-01,  3.3152e-02, -1.9660e-01, -2.0685e-01, -4.0774e-02,\n",
       "          3.6426e-01, -3.2682e-01, -1.9788e-02, -9.1704e-04,  3.2173e-02,\n",
       "          3.3403e-02,  5.0371e-03,  9.9775e-02, -7.8423e-02, -3.1939e-01,\n",
       "         -1.5235e-01, -1.9975e-01,  5.9505e-02,  4.3722e-01,  4.0477e-01,\n",
       "         -2.4540e-01, -2.5384e-01,  2.2848e-02, -1.0352e-01, -1.7819e-01,\n",
       "          3.5911e-01, -4.2524e-02,  2.8852e-01, -3.5532e-01, -2.5925e-01,\n",
       "         -1.3864e-01,  1.6773e-01,  1.5595e-01, -2.5214e-01,  2.7468e-01,\n",
       "         -1.8588e-01, -1.0912e-01,  5.1252e-01,  1.7360e-01,  1.6635e-01,\n",
       "         -7.0178e-02,  8.0418e-02, -4.0623e-01, -1.8805e-01,  1.6167e-02,\n",
       "          2.3290e-01, -3.8708e-01, -2.1603e-01, -6.3610e-02,  1.0694e-02,\n",
       "          3.2654e-01,  1.8559e-01,  1.6480e-01,  9.4932e-02, -5.7958e-02,\n",
       "         -6.7544e-02, -2.2123e-01,  2.6493e-02, -1.2413e-03,  9.8148e-02,\n",
       "         -1.8844e-01,  3.9066e-01, -4.0639e-01,  2.1637e-01,  3.5934e-01,\n",
       "          1.2082e-01, -3.6035e-01,  4.4839e-01,  1.7866e-01,  7.2310e-02,\n",
       "         -1.7727e-01, -1.4113e-01,  2.5085e-01, -1.5482e-01,  2.8027e-01,\n",
       "         -2.7814e-02,  1.8432e-01, -2.1166e-01, -5.4803e-01,  3.7630e-02,\n",
       "         -1.3797e-01,  4.7231e-02, -1.9282e-01,  1.9907e-01, -3.2394e-01,\n",
       "          1.2992e-01,  5.3495e-01,  3.0986e-01, -2.5030e-01,  3.0594e-02,\n",
       "          2.0388e-01, -2.3948e-01,  4.4131e-02,  4.3189e-02, -1.8266e-01,\n",
       "         -2.4148e-01,  1.6807e-01,  2.5877e-01,  2.8066e-01,  4.5670e-01,\n",
       "         -3.9752e-01, -2.5212e-01, -5.4480e-02,  2.2974e-01, -1.0663e-01,\n",
       "          1.8813e-01, -1.7615e-02, -6.9251e-02, -5.0439e-02,  2.4535e-01,\n",
       "         -1.9301e-01,  6.1863e-02, -1.7935e-02]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = sim_cse_tokenizer(\"test, hello\", return_tensors=\"pt\")\n",
    "o = simccse(**out) \n",
    "torch.flatten(o.pooler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_sim_cse(messages: list[str]) -> list[float]:\n",
    "    scores = []\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model.eval()\n",
    "\n",
    "    h = []\n",
    "    for message in messages:\n",
    "        tokens = sim_cse_tokenizer(message, return_tensors=\"pt\")\n",
    "        output = simccse(**tokens)\n",
    "        h.append(torch.flatten(output.pooler_output))\n",
    "\n",
    "    for i in range(len(messages) - 1):\n",
    "        j = i + 1\n",
    "\n",
    "        tokenized_input = {}\n",
    "        if tokenizer:\n",
    "            tokenized_input = tokenizer(\n",
    "                messages[i], messages[j], max_length=45, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model.forward(**tokenized_input).logits\n",
    "\n",
    "        cos_sim = cosine_similarity(h[i], h[j],  dim=0)\n",
    "        score = F.softmax(logits, dim=1)[0][0]\n",
    "\n",
    "        # print(h[i])\n",
    "        # print(h[j])\n",
    "\n",
    "        # print(score)\n",
    "        scores.append((score.item() * 0.5 + 0.5 * cos_sim.item()))\n",
    "        # print(score.item())\n",
    "        # print(logits)\n",
    "        # score = float(logits[0][0] > logits[0][1])\n",
    "        # print(score)\n",
    "        # scores.append(score)\n",
    "\n",
    "    model.train()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [01:14,  1.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2984428859102616"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_sim_cse, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [01:14,  1.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2965193623779101"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_sim_cse, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:20,  1.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3401264047570903"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_all_mpnet, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:30,  1.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41600840826684643"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, thr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:30,  1.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30692733444408804"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:42,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34237948340789404"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:32,  1.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37644891407645986"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not trained\n",
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:32,  1.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3290268482839446"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not trained\n",
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:30,  1.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9616573796789396"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:30,  1.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4553471084299834"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:32,  1.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34237948340789404"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:32,  1.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5687826951299265"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:32,  1.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4553471084299834"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:25,  1.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.439999519903291"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:25,  1.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3963929229019702"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:26,  1.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3927847767476985"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:24,  1.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42016731702311494"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:24,  1.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.439999519903291"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:25,  1.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35825837425069373"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_windowdiff(test_df[:40], scorer=scorer_trained_bert, smoothing_strategy=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0]\n",
      "[ 1  2  3  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n",
      " 28 29 30 32 33 34 35 36 37 38 39 40 41]\n",
      "[1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    segment_dialog(situation_text, scorer=scorer_all_mpnet, smoothing_strategy=\"depth\")[\n",
    "        0\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    segment_dialog(situation_text, scorer=scorer_all_mpnet, smoothing_strategy=\"depth\")[\n",
    "        1\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    segment_dialog(situation_text, scorer=scorer_all_mpnet, smoothing_strategy=None)[0]\n",
    ")\n",
    "print(\n",
    "    segment_dialog(situation_text, scorer=scorer_all_mpnet, smoothing_strategy=None)[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could I be of any help to you ? \n",
      " I want to buy a skirt , but I have no idea which one to buy . \n",
      " Do you like miniskirt ? It's popular among young girls . The pleated skirt also sells well . \n",
      " I don't like to keep up with joneses . \n",
      " What about the divided skirt ? \n",
      " I think this suits me . Can I try it on ? \n",
      "======\n",
      "Excuse me , ma ’ am ? \n",
      " Yes . What can I do for you ? \n",
      " I ’ m new here and I can ’ t seem to find the lunch room . \n",
      " Oh , it ’ s right downstairs . I ’ m going there myself . Just follow me . \n",
      "======\n",
      "My name is Mary , and I will be your server this evening . \n",
      " Hi Mary . We are really looking forward to a great meal here . \n",
      " Can I interest you in an appetizer to start out ? \n",
      " I would love an appetizer . Are they listed in the menu ? \n",
      " We have our daily appetizers listed on the board over there on the wall . \n",
      " I am thinking about the popcorn shrimp . How is that ? \n",
      " That would be a great choice ! \n",
      " I'll trust your taste and take one order of that . \n",
      " We have a special where you can order a second appetizer for half price . \n",
      " In that case , we'll take an order of onion rings with our first choice . \n",
      "======\n",
      "What's the temperature today ? \n",
      " It's about 5 degrees centigrade . \n",
      " What's the weather forecast for tomorrow ? \n",
      " The weatherman says it's going to snow tomorrow . \n",
      " Are you used to the climate here ? \n",
      " I think I'll soon get used to it . \n",
      "------\n",
      " What is the average temperature of Beijing ? \n",
      " lt's about 180C , but in winter the temperature may fall to 10-15 degrees below zero . And we have a long winter . \n",
      " Which season do you like best ? \n",
      " I prefer spring when little by little everything becomes green and the weather is almost always nice . \n",
      "======\n",
      "Where shall we go on vacation this summer ? \n",
      " Well , that depends . Tell me where you want to go ? \n",
      " Venice . I have great interests in the boats . \n",
      " That's interesting to travel by boat to see the whole city that is between the sea and sky . But personally I like Greek better . \n",
      " I like the country too . It's quite famous for its culture . \n"
     ]
    }
   ],
   "source": [
    "situation = test_df.loc[14]\n",
    "situation_text = situation[\"messages\"]\n",
    "orig_boundaries_mask = situation[\"boundaries_mask\"]\n",
    "pred_boundaries_mask = segment_dialog(\n",
    "    situation_text, scorer=scorer_all_mpnet, smoothing_strategy=\"depth\"\n",
    ")[1]\n",
    "\n",
    "for num, message in enumerate(situation_text):\n",
    "    print(message.replace(\"\\n\", \"\"))\n",
    "    if num < len(orig_boundaries_mask) and orig_boundaries_mask[num]:\n",
    "        print(\"======\")\n",
    "\n",
    "    if num < len(pred_boundaries_mask) and pred_boundaries_mask[num]:\n",
    "        print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mean_windowdiff(test_df, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
